/**
 * 模型目录 — 前端静态数据
 * 与 packages/brain/src/llm/router.ts 中的 KNOWN_MODELS 同步
 */

export type ModelEntry = {
  id: string;
  name: string;
  description: string;
  purposes: string[];
  tier: "premium" | "standard" | "budget";
  costPer1MInput: number;
  costPer1MOutput: number;
  maxContext: number;
  vision: boolean;
  reasoning: boolean;
  toolUse: boolean;
  recommended: boolean;
};

export type ModelGroup = {
  label: string;
  models: ModelEntry[];
};

export type ProviderCatalog = {
  groups?: ModelGroup[];
  models?: ModelEntry[];
};

// ─── Anthropic ────────────────────────────────

const ANTHROPIC_MODELS: ModelEntry[] = [
  {
    id: "claude-opus-4-6-20260203",
    name: "Claude Opus 4.6",
    description: "旗舰推理模型，百万上下文",
    purposes: ["chat", "reasoning", "coding", "tool_use"],
    tier: "premium",
    costPer1MInput: 5,
    costPer1MOutput: 25,
    maxContext: 1000000,
    vision: true,
    reasoning: true,
    toolUse: true,
    recommended: false,
  },
  {
    id: "claude-sonnet-4-5-20250514",
    name: "Claude Sonnet 4.5",
    description: "性能与成本最佳平衡，推荐日常使用",
    purposes: ["chat", "reasoning", "coding", "tool_use"],
    tier: "standard",
    costPer1MInput: 3,
    costPer1MOutput: 15,
    maxContext: 200000,
    vision: true,
    reasoning: true,
    toolUse: true,
    recommended: true,
  },
  {
    id: "claude-haiku-3-5-20241022",
    name: "Claude Haiku 3.5",
    description: "轻量快速，适合简单任务和批量处理",
    purposes: ["chat", "summarization", "extraction", "tool_use"],
    tier: "budget",
    costPer1MInput: 0.8,
    costPer1MOutput: 4,
    maxContext: 200000,
    vision: true,
    reasoning: false,
    toolUse: true,
    recommended: true,
  },
];

// ─── OpenAI ───────────────────────────────────

const OPENAI_MODELS: ModelEntry[] = [
  {
    id: "gpt-5.2",
    name: "GPT-5.2",
    description: "最新旗舰，全能推理与创作",
    purposes: ["chat", "reasoning", "coding", "tool_use"],
    tier: "premium",
    costPer1MInput: 1.75,
    costPer1MOutput: 14,
    maxContext: 400000,
    vision: true,
    reasoning: true,
    toolUse: true,
    recommended: true,
  },
  {
    id: "gpt-5.1-codex",
    name: "GPT-5.1 Codex",
    description: "专业编程模型，代码生成能力顶尖",
    purposes: ["coding", "reasoning", "chat", "tool_use"],
    tier: "standard",
    costPer1MInput: 1.07,
    costPer1MOutput: 8.5,
    maxContext: 400000,
    vision: true,
    reasoning: true,
    toolUse: true,
    recommended: false,
  },
  {
    id: "o4-mini",
    name: "o4-mini",
    description: "深度推理模型，擅长复杂逻辑分析",
    purposes: ["reasoning", "coding", "chat", "tool_use"],
    tier: "standard",
    costPer1MInput: 1.1,
    costPer1MOutput: 4.4,
    maxContext: 200000,
    vision: true,
    reasoning: true,
    toolUse: true,
    recommended: true,
  },
  {
    id: "gpt-5-mini",
    name: "GPT-5 Mini",
    description: "轻量版 GPT-5，高性价比日常使用",
    purposes: ["chat", "coding", "summarization", "tool_use"],
    tier: "budget",
    costPer1MInput: 0.25,
    costPer1MOutput: 2,
    maxContext: 400000,
    vision: true,
    reasoning: false,
    toolUse: true,
    recommended: false,
  },
  {
    id: "gpt-5.1-codex-mini",
    name: "GPT-5.1 Codex Mini",
    description: "轻量编程模型，快速代码补全",
    purposes: ["coding", "chat", "summarization", "tool_use"],
    tier: "budget",
    costPer1MInput: 0.25,
    costPer1MOutput: 2,
    maxContext: 400000,
    vision: true,
    reasoning: false,
    toolUse: true,
    recommended: false,
  },
  {
    id: "gpt-4o",
    name: "GPT-4o",
    description: "经典多模态模型，支持音频输入",
    purposes: ["chat", "coding", "summarization", "tool_use"],
    tier: "standard",
    costPer1MInput: 2.5,
    costPer1MOutput: 10,
    maxContext: 128000,
    vision: true,
    reasoning: false,
    toolUse: true,
    recommended: false,
  },
  {
    id: "gpt-4o-mini",
    name: "GPT-4o Mini",
    description: "最便宜的 OpenAI 模型，批量任务首选",
    purposes: ["chat", "summarization", "extraction", "tool_use"],
    tier: "budget",
    costPer1MInput: 0.15,
    costPer1MOutput: 0.6,
    maxContext: 128000,
    vision: true,
    reasoning: false,
    toolUse: true,
    recommended: true,
  },
];

// ─── Google Gemini ────────────────────────────

const GOOGLE_MODELS: ModelEntry[] = [
  {
    id: "gemini-3-pro-preview",
    name: "Gemini 3 Pro",
    description: "最新旗舰，百万上下文多模态",
    purposes: ["chat", "reasoning", "coding", "tool_use"],
    tier: "premium",
    costPer1MInput: 2,
    costPer1MOutput: 12,
    maxContext: 1048576,
    vision: true,
    reasoning: true,
    toolUse: true,
    recommended: false,
  },
  {
    id: "gemini-3-flash-preview",
    name: "Gemini 3 Flash",
    description: "速度与质量兼备的最佳选择",
    purposes: ["chat", "reasoning", "coding", "tool_use"],
    tier: "standard",
    costPer1MInput: 0.5,
    costPer1MOutput: 3,
    maxContext: 1048576,
    vision: true,
    reasoning: true,
    toolUse: true,
    recommended: true,
  },
  {
    id: "gemini-2.5-pro",
    name: "Gemini 2.5 Pro",
    description: "成熟稳定的推理模型",
    purposes: ["chat", "reasoning", "coding", "tool_use"],
    tier: "standard",
    costPer1MInput: 1.25,
    costPer1MOutput: 10,
    maxContext: 1048576,
    vision: true,
    reasoning: true,
    toolUse: true,
    recommended: false,
  },
  {
    id: "gemini-2.5-flash",
    name: "Gemini 2.5 Flash",
    description: "高性价比快速模型",
    purposes: ["chat", "reasoning", "coding", "tool_use"],
    tier: "budget",
    costPer1MInput: 0.3,
    costPer1MOutput: 2.5,
    maxContext: 1048576,
    vision: true,
    reasoning: true,
    toolUse: true,
    recommended: true,
  },
  {
    id: "gemini-2.0-flash",
    name: "Gemini 2.0 Flash",
    description: "超低成本，简单任务专用",
    purposes: ["chat", "summarization", "extraction", "tool_use"],
    tier: "budget",
    costPer1MInput: 0.1,
    costPer1MOutput: 0.4,
    maxContext: 1048576,
    vision: true,
    reasoning: false,
    toolUse: true,
    recommended: false,
  },
];

// ─── DeepSeek ─────────────────────────────────

const DEEPSEEK_MODELS: ModelEntry[] = [
  {
    id: "deepseek-chat",
    name: "DeepSeek V3.2 Chat",
    description: "通用对话，极致性价比",
    purposes: ["chat", "coding", "summarization", "tool_use"],
    tier: "budget",
    costPer1MInput: 0.28,
    costPer1MOutput: 0.42,
    maxContext: 128000,
    vision: false,
    reasoning: false,
    toolUse: true,
    recommended: true,
  },
  {
    id: "deepseek-reasoner",
    name: "DeepSeek V3.2 Reasoner",
    description: "深度推理模型，数学逻辑突出",
    purposes: ["reasoning", "coding", "chat"],
    tier: "budget",
    costPer1MInput: 0.28,
    costPer1MOutput: 0.42,
    maxContext: 128000,
    vision: false,
    reasoning: true,
    toolUse: true,
    recommended: true,
  },
];

// ─── NVIDIA NIM ───────────────────────────────

const NVIDIA_QWEN: ModelEntry[] = [
  {
    id: "qwen/qwen3-235b-a22b",
    name: "Qwen3 235B-A22B",
    description: "MoE 旗舰，bench #13: 7.2s 均值偏慢",
    purposes: ["chat", "reasoning", "coding", "tool_use"],
    tier: "budget",
    costPer1MInput: 0,
    costPer1MOutput: 0,
    maxContext: 131072,
    vision: false,
    reasoning: true,
    toolUse: true,
    recommended: false,
  },
  {
    id: "qwen/qwen3-coder-480b-a35b-instruct",
    name: "Qwen3 Coder 480B",
    description: "推荐默认，bench #6: 1.9s 均值，复杂任务自动 write+run",
    purposes: ["coding", "reasoning", "tool_use"],
    tier: "premium",
    costPer1MInput: 0,
    costPer1MOutput: 0,
    maxContext: 262144,
    vision: false,
    reasoning: true,
    toolUse: true,
    recommended: true,
  },
  {
    id: "qwen/qwen3-next-80b-a3b-instruct",
    name: "Qwen3-Next 80B Instruct",
    description: "bench #10: 5.2s 均值，复杂任务 12.7s 偏慢",
    purposes: ["chat", "reasoning", "coding", "tool_use"],
    tier: "standard",
    costPer1MInput: 0,
    costPer1MOutput: 0,
    maxContext: 262144,
    vision: false,
    reasoning: false,
    toolUse: true,
    recommended: false,
  },
  {
    id: "qwen/qwen3-next-80b-a3b-thinking",
    name: "Qwen3-Next 80B Thinking",
    description: "推理增强版，深度思维链",
    purposes: ["reasoning", "coding", "chat"],
    tier: "standard",
    costPer1MInput: 0,
    costPer1MOutput: 0,
    maxContext: 131072,
    vision: false,
    reasoning: true,
    toolUse: true,
    recommended: false,
  },
  {
    id: "qwen/qwq-32b",
    name: "QwQ-32B",
    description: "深度推理，小而精悍",
    purposes: ["reasoning", "coding", "chat"],
    tier: "standard",
    costPer1MInput: 0,
    costPer1MOutput: 0,
    maxContext: 131072,
    vision: false,
    reasoning: true,
    toolUse: true,
    recommended: false,
  },
  {
    id: "qwen/qwen2.5-coder-32b-instruct",
    name: "Qwen2.5 Coder 32B",
    description: "经典编程模型",
    purposes: ["coding", "chat", "tool_use"],
    tier: "budget",
    costPer1MInput: 0,
    costPer1MOutput: 0,
    maxContext: 32768,
    vision: false,
    reasoning: false,
    toolUse: true,
    recommended: false,
  },
];

const NVIDIA_KIMI: ModelEntry[] = [
  {
    id: "moonshotai/kimi-k2-instruct-0905",
    name: "Kimi K2 Instruct 0905",
    description: "最快版 K2，低延迟首选",
    purposes: ["chat", "coding", "summarization", "tool_use"],
    tier: "standard",
    costPer1MInput: 0,
    costPer1MOutput: 0,
    maxContext: 131072,
    vision: false,
    reasoning: false,
    toolUse: true,
    recommended: false,
  },
  {
    id: "moonshotai/kimi-k2-instruct",
    name: "Kimi K2 Instruct",
    description: "bench #8: 2.6s 均值，中文能力好",
    purposes: ["chat", "coding", "summarization", "tool_use"],
    tier: "standard",
    costPer1MInput: 0,
    costPer1MOutput: 0,
    maxContext: 131072,
    vision: false,
    reasoning: false,
    toolUse: true,
    recommended: false,
  },
  {
    id: "moonshotai/kimi-k2-thinking",
    name: "Kimi K2 Thinking",
    description: "深度推理版，精准简洁",
    purposes: ["reasoning", "coding", "chat"],
    tier: "premium",
    costPer1MInput: 0,
    costPer1MOutput: 0,
    maxContext: 131072,
    vision: false,
    reasoning: true,
    toolUse: true,
    recommended: false,
  },
  {
    id: "moonshotai/kimi-k2.5",
    name: "Kimi K2.5",
    description: "1T MoE 多模态，262K 上下文",
    purposes: ["chat", "reasoning", "coding", "tool_use"],
    tier: "premium",
    costPer1MInput: 0,
    costPer1MOutput: 0,
    maxContext: 262144,
    vision: true,
    reasoning: true,
    toolUse: true,
    recommended: true,
  },
];

const NVIDIA_MINIMAX: ModelEntry[] = [
  {
    id: "minimaxai/minimax-m2",
    name: "MiniMax M2",
    description: "230B MoE，太慢不推荐 (15s+34s)",
    purposes: ["chat", "reasoning", "coding", "tool_use"],
    tier: "budget",
    costPer1MInput: 0,
    costPer1MOutput: 0,
    maxContext: 128000,
    vision: false,
    reasoning: true,
    toolUse: true,
    recommended: false,
  },
  {
    id: "minimaxai/minimax-m2.1",
    name: "MiniMax M2.1",
    description: "太慢不推荐 (15s+34s)",
    purposes: ["chat", "reasoning", "coding", "tool_use"],
    tier: "budget",
    costPer1MInput: 0,
    costPer1MOutput: 0,
    maxContext: 128000,
    vision: false,
    reasoning: true,
    toolUse: true,
    recommended: false,
  },
];

const NVIDIA_OTHER: ModelEntry[] = [
  {
    id: "meta/llama-3.3-70b-instruct",
    name: "Llama 3.3 70B",
    description: "bench #1: 0.8s 最快，工具调用稳定",
    purposes: ["chat", "coding", "summarization", "tool_use"],
    tier: "standard",
    costPer1MInput: 0,
    costPer1MOutput: 0,
    maxContext: 128000,
    vision: false,
    reasoning: false,
    toolUse: true,
    recommended: true,
  },
  {
    id: "meta/llama-4-scout-17b-16e-instruct",
    name: "Llama 4 Scout 17B",
    description: "bench #2: 0.8s，524K 上下文，工具调用稳定",
    purposes: ["chat", "coding", "summarization", "tool_use"],
    tier: "standard",
    costPer1MInput: 0,
    costPer1MOutput: 0,
    maxContext: 524288,
    vision: false,
    reasoning: false,
    toolUse: true,
    recommended: true,
  },
  {
    id: "stepfun-ai/step-3.5-flash",
    name: "Step 3.5 Flash",
    description: "bench #3: 1.5s 均值，工具调用稳定",
    purposes: ["chat", "coding", "summarization", "tool_use"],
    tier: "standard",
    costPer1MInput: 0,
    costPer1MOutput: 0,
    maxContext: 131072,
    vision: false,
    reasoning: false,
    toolUse: true,
    recommended: false,
  },
  {
    id: "meta/llama-3.1-405b-instruct",
    name: "Llama 3.1 405B",
    description: "bench #4: 1.8s，复杂任务自动 write+run",
    purposes: ["chat", "reasoning", "coding", "summarization", "tool_use"],
    tier: "premium",
    costPer1MInput: 0,
    costPer1MOutput: 0,
    maxContext: 128000,
    vision: false,
    reasoning: true,
    toolUse: true,
    recommended: false,
  },
  {
    id: "openai/gpt-oss-120b",
    name: "GPT-OSS 120B",
    description: "bench #5: 1.9s 均值，工具调用稳定",
    purposes: ["chat", "coding", "summarization", "tool_use"],
    tier: "standard",
    costPer1MInput: 0,
    costPer1MOutput: 0,
    maxContext: 131072,
    vision: false,
    reasoning: false,
    toolUse: true,
    recommended: false,
  },
  {
    id: "deepseek-ai/deepseek-v3.1",
    name: "DeepSeek V3.1 (NIM)",
    description: "bench #7: 2.6s 均值，工具调用稳定",
    purposes: ["chat", "coding", "summarization", "tool_use"],
    tier: "standard",
    costPer1MInput: 0,
    costPer1MOutput: 0,
    maxContext: 131072,
    vision: false,
    reasoning: false,
    toolUse: true,
    recommended: false,
  },
  {
    id: "nvidia/llama-3.1-nemotron-ultra-253b-v1",
    name: "Nemotron Ultra 253B",
    description: "bench #9: 2.7s 均值，NVIDIA 自研推理旗舰",
    purposes: ["chat", "reasoning", "coding"],
    tier: "premium",
    costPer1MInput: 0,
    costPer1MOutput: 0,
    maxContext: 131072,
    vision: false,
    reasoning: true,
    toolUse: true,
    recommended: false,
  },
  {
    id: "nvidia/nemotron-3-nano-30b-a3b",
    name: "Nemotron 3 Nano 30B",
    description: "百万上下文轻量模型",
    purposes: ["chat", "coding", "reasoning"],
    tier: "standard",
    costPer1MInput: 0,
    costPer1MOutput: 0,
    maxContext: 1048576,
    vision: false,
    reasoning: true,
    toolUse: true,
    recommended: false,
  },
  {
    id: "deepseek-ai/deepseek-r1",
    name: "DeepSeek R1 (NIM)",
    description: "DeepSeek 推理模型 NIM 版",
    purposes: ["reasoning", "coding", "chat"],
    tier: "standard",
    costPer1MInput: 0,
    costPer1MOutput: 0,
    maxContext: 65536,
    vision: false,
    reasoning: true,
    toolUse: false,
    recommended: false,
  },
  {
    id: "deepseek-ai/deepseek-v3.2",
    name: "DeepSeek V3.2 (NIM)",
    description: "DeepSeek 通用模型 NIM 版",
    purposes: ["chat", "coding", "summarization"],
    tier: "budget",
    costPer1MInput: 0,
    costPer1MOutput: 0,
    maxContext: 163840,
    vision: false,
    reasoning: false,
    toolUse: true,
    recommended: false,
  },
  {
    id: "nvidia/nemotron-nano-12b-v2-vl",
    name: "Nemotron Nano 12B VL",
    description: "轻量视觉语言模型",
    purposes: ["chat", "extraction", "summarization"],
    tier: "budget",
    costPer1MInput: 0,
    costPer1MOutput: 0,
    maxContext: 128000,
    vision: true,
    reasoning: false,
    toolUse: false,
    recommended: false,
  },
];

// ─── 按 Provider 汇总 ────────────────────────

export const MODEL_CATALOG: Record<string, ProviderCatalog> = {
  anthropic: { models: ANTHROPIC_MODELS },
  openai: { models: OPENAI_MODELS },
  google: { models: GOOGLE_MODELS },
  deepseek: { models: DEEPSEEK_MODELS },
  nvidia: {
    groups: [
      { label: "Qwen 系列", models: NVIDIA_QWEN },
      { label: "Kimi 系列 (Moonshot AI)", models: NVIDIA_KIMI },
      { label: "MiniMax 系列", models: NVIDIA_MINIMAX },
      { label: "其他模型", models: NVIDIA_OTHER },
    ],
  },
  local: { models: [] },
};

/** 获取某个 provider 的所有模型（扁平列表） */
export function getAllModels(provider: string): ModelEntry[] {
  const catalog = MODEL_CATALOG[provider];
  if (!catalog) return [];
  if (catalog.models) return catalog.models;
  if (catalog.groups) return catalog.groups.flatMap((g) => g.models);
  return [];
}

/** 获取某个 provider 的推荐默认模型 */
export function getDefaultModels(provider: string): string[] {
  return getAllModels(provider)
    .filter((m) => m.recommended)
    .map((m) => m.id);
}
